{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a7b312-3258-4214-8912-8fbbd4b0cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6aa5d-48ab-4fde-8570-8431d33ab1b5",
   "metadata": {},
   "source": [
    "# Read EA CH indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29be93b1-0fd2-4ca1-8caa-8e8910daf15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_explicit_indexes = pd.read_csv('../Data/CH_Anti_Asian_hate_explicit_indexes.csv')\n",
    "CH_implicit_indexes = pd.read_csv('../Data/CH_Anti_Asian_hate_implicit_indexes.csv')\n",
    "EA_explicit_indexes = pd.read_csv('../Data/EA_dev_hostile_explicit_ids.csv')\n",
    "EA_implicit_indexes = pd.read_csv('../Data/EA_dev_hostile_implicit_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30090360-695f-426b-9224-9f335959ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_annotated_tweets = pd.read_csv('../Data/annotated_tweets_w_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920f2c14-afd6-4bda-9cef-5b6ea2ffcc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1344\n",
       "1     517\n",
       "2     429\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH_annotated_tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b70f552-2e53-4ce2-aafc-f9c965a739fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_annotated_tweets_explicit = CH_annotated_tweets[CH_annotated_tweets.index.isin(CH_explicit_indexes['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48e91c2-2bec-421d-9509-732ee94d61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_annotated_tweets_implicit = CH_annotated_tweets[CH_annotated_tweets.index.isin(CH_implicit_indexes['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bce8159-70c6-45c1-b722-db23f8f8afc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    331\n",
       "1    127\n",
       "2     82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH_annotated_tweets_explicit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c2fbbf-e717-4b8c-b51d-90eb695c3d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    83\n",
       "1    31\n",
       "2    27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH_annotated_tweets_implicit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1976d-5671-4c3b-a864-94302d676edb",
   "metadata": {},
   "source": [
    "# Prepare CH_explicit.txt and CH_implicit.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8392671-8372-41da-8a60-63b41ef5a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/CH_explicit.txt', 'w') as file:\n",
    "    file.write('\\n\\n'.join(CH_annotated_tweets_explicit['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "540c7de4-6591-4e2d-9199-b45858c04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/CH_implicit.txt', 'w') as file:\n",
    "    file.write('\\n\\n'.join(CH_annotated_tweets_implicit['Text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528bffe-35ab-484e-9ab3-31a9de97e218",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare random_stopword_tweets.txt\n",
    "Because the authors didn't include this txt file in the repository, I can only try to find some alternative. I found one data that might be a good substitute for this data set (http://help.sentiment140.com/for-students/). Then I included the text of 2000 random tweets, separated by double newlines.\n",
    "\n",
    "The data is a CSV with emoticons removed. Data file format has 6 fields:\n",
    "- 0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "- 1 - the id of the tweet (2087)\n",
    "- 2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "- 3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- 4 - the user that tweeted (robotickilldozr)\n",
    "- 5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f772afe-8413-44a3-a7bd-db0f9ca34a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = ['polarity_label','tweet_id','date','query','user','text']\n",
    "tweets_all = pd.read_csv('../Data/training_tweets_sentiments.csv', names=name_col, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f725ea19-037c-4072-898a-d84e82844733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = tweets_all.sample(n=2000, random_state=2023)\n",
    "with open('../Data/random_stopword_tweets.txt', 'w') as file:\n",
    "    file.write('\\n\\n'.join(sample_df['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm_bert",
   "language": "python",
   "name": "atm_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
