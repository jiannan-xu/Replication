{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6fa483-2dcb-4c2c-ab81-e3139b9f6581",
   "metadata": {},
   "source": [
    "# Generate Wiki data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f5c70a-6ec9-4474-8938-e4459049c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292483/711131892.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  toxic_train_pruned = data[data['split']=='train' ][data['wiki_topic'].isin(topic_categories[1]+topic_categories[2])]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "comments = pd.read_csv('../Data/toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)  #from https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973\n",
    "annotations = pd.read_csv('../Data/toxicity_annotations.tsv',  sep = '\\t')\n",
    "# join labels and comments\n",
    "comments['toxicity'] = annotations.groupby('rev_id')['toxicity'].mean() > 0.5\n",
    "\n",
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x:re.sub(r'[^A-Za-z0-9 ]+', ' ', x).lower())\n",
    "\n",
    "wiki_topics = pd.read_csv('../Data/wiki_toxicity_topics.csv', index_col=[0]) #from this repo\n",
    "\n",
    "data = comments.merge(wiki_topics, on='rev_id')  #merge the two datasets\n",
    "\n",
    "#pruned Wiki-toxic \n",
    "topic_categories={1:[0,1],\n",
    "                  2:[2,7,8,9,12,14,16],\n",
    "                  3:[3,4,5,6,10,11,13,15,17,18,19]}\n",
    "\n",
    "\n",
    "toxic_train_pruned = data[data['split']=='train' ][data['wiki_topic'].isin(topic_categories[1]+topic_categories[2])]\n",
    "toxic_test = data[data['split']=='test']\n",
    "toxic_dev = data[data['split']=='dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6f5f4b-b002-40e6-a36d-14ea5167f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_train_pruned.to_csv('../Data/toxic/toxic_train_pruned.csv')\n",
    "toxic_test.to_csv('../Data/toxic/toxic_test.csv')\n",
    "toxic_dev.to_csv('../Data/toxic/toxic_dev.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm_bert",
   "language": "python",
   "name": "atm_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
